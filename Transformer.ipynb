{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "niDE637DJruy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import BPE\n",
        "from tokenizers.trainers import BpeTrainer\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "import pandas as pd\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KGn2ieKFJ90f"
      },
      "outputs": [],
      "source": [
        "def load_training_data(file_path):\n",
        "    \"\"\"Load the training data from the JSON file.\"\"\"\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "    train_data = data['English-Bengali']['Train']\n",
        "    source_sentences = [entry['source'] for entry in train_data.values()]\n",
        "    target_sentences = [entry['target'] for entry in train_data.values()]\n",
        "    return source_sentences, target_sentences\n",
        "\n",
        "def load_validation_data(file_path):\n",
        "    \"\"\"Load the validation data from the JSON file.\"\"\"\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "    val_data = data['English-Bengali']['Test']\n",
        "    val_sentences = {key: entry['source'] for key, entry in val_data.items()}\n",
        "    return val_sentences\n",
        "\n",
        "def save_translations(translations, output_file):\n",
        "    \"\"\"Save the translated sentences to a JSON file.\"\"\"\n",
        "    with open(output_file, 'w', encoding='utf-8') as f:\n",
        "        json.dump(translations, f, ensure_ascii=False, indent=4)\n",
        "    print(f\"Translations saved to {output_file}\")\n",
        "\n",
        "def pad_sequences(sequences, maxlen, padding_value=0):\n",
        "    \"\"\"Pad sequences to the same length.\"\"\"\n",
        "    return np.array([seq + [padding_value] * (maxlen - len(seq)) if len(seq) < maxlen else seq[:maxlen] for seq in sequences])\n",
        "\n",
        "def train_bpe_tokenizer(sentences, vocab_size, tokenizer_path):\n",
        "    \"\"\"Train a BPE tokenizer.\"\"\"\n",
        "    tokenizer = Tokenizer(BPE())\n",
        "    tokenizer.pre_tokenizer = Whitespace()\n",
        "    trainer = BpeTrainer(vocab_size=vocab_size, special_tokens=[\"<PAD>\", \"<UNK>\", \"<BOS>\", \"<EOS>\"])\n",
        "    tokenizer.train_from_iterator(sentences, trainer)\n",
        "    tokenizer.save(tokenizer_path)\n",
        "    print(f\"Tokenizer saved to {tokenizer_path}\")\n",
        "    return tokenizer\n",
        "\n",
        "def load_bpe_tokenizer(tokenizer_path):\n",
        "    \"\"\"Load a pre-trained BPE tokenizer.\"\"\"\n",
        "    return Tokenizer.from_file(tokenizer_path)\n",
        "\n",
        "def encode_sentences(tokenizer, sentences, max_len):\n",
        "    \"\"\"Encode and pad sentences.\"\"\"\n",
        "    tokenized = [tokenizer.encode(sentence).ids for sentence in sentences]\n",
        "    return pad_sequences(tokenized, maxlen=max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JSRnWYGFJ_Yj"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 3. Custom Dataset\n",
        "\n",
        "\n",
        "class TranslationDataset(Dataset):\n",
        "    \"\"\"Custom dataset for machine translation.\"\"\"\n",
        "    def __init__(self, source_sentences, target_sentences):\n",
        "        self.source_sentences = source_sentences\n",
        "        self.target_sentences = target_sentences\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.source_sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.source_sentences[idx]), torch.tensor(self.target_sentences[idx])\n",
        "\n",
        "def collate_fn(batch):\n",
        "    \"\"\"Collate function for dynamic padding in DataLoader.\"\"\"\n",
        "    src, tgt = zip(*batch)\n",
        "    src = torch.nn.utils.rnn.pad_sequence(src, batch_first=True, padding_value=0)\n",
        "    tgt = torch.nn.utils.rnn.pad_sequence(tgt, batch_first=True, padding_value=0)\n",
        "    return src, tgt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MeWnaEDZKC8q"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 2. Attention Mechanisms\n",
        "\n",
        "\n",
        "class ScaledDotProductAttention(nn.Module):\n",
        "    \"\"\"Scaled Dot-Product Attention\"\"\"\n",
        "    def __init__(self):\n",
        "        super(ScaledDotProductAttention, self).__init__()\n",
        "\n",
        "    def forward(self, query, key, value, mask=None):\n",
        "        d_k = query.size(-1)\n",
        "        scores = torch.matmul(query, key.transpose(-2, -1)) / np.sqrt(d_k)\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, -1e9)\n",
        "        attention = torch.softmax(scores, dim=-1)\n",
        "        output = torch.matmul(attention, value)\n",
        "        return output, attention\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\"Multi-Head Attention\"\"\"\n",
        "    def __init__(self, embed_size, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        assert embed_size % num_heads == 0, \"Embedding size must be divisible by the number of heads\"\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = embed_size // num_heads\n",
        "        self.query_linear = nn.Linear(embed_size, embed_size)\n",
        "        self.key_linear = nn.Linear(embed_size, embed_size)\n",
        "        self.value_linear = nn.Linear(embed_size, embed_size)\n",
        "        self.fc_out = nn.Linear(embed_size, embed_size)\n",
        "\n",
        "    def forward(self, query, key, value, mask=None):\n",
        "        batch_size = query.size(0)\n",
        "        query = self.query_linear(query)\n",
        "        key = self.key_linear(key)\n",
        "        value = self.value_linear(value)\n",
        "\n",
        "        query = query.view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        key = key.view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        value = value.view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "\n",
        "        attention_output, _ = ScaledDotProductAttention()(query, key, value, mask)\n",
        "\n",
        "        attention_output = attention_output.transpose(1, 2).contiguous()\n",
        "        attention_output = attention_output.view(batch_size, -1, self.num_heads * self.head_dim)\n",
        "\n",
        "        output = self.fc_out(attention_output)\n",
        "        return output\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5P_7lObtKFfL"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 3. Transformer Components\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    \"\"\"Feedforward Neural Network Layer\"\"\"\n",
        "    def __init__(self, embed_size, ff_hidden_size, dropout=0.1):\n",
        "        super(FeedForward, self).__init__()\n",
        "        self.linear1 = nn.Linear(embed_size, ff_hidden_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear2 = nn.Linear(ff_hidden_size, embed_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear2(self.dropout(torch.relu(self.linear1(x))))\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    \"\"\"Positional Encoding for sequences\"\"\"\n",
        "    def __init__(self, embed_size, max_len=1000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        pe = torch.zeros(max_len, embed_size)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, embed_size, 2).float() * (-np.log(10000.0) / embed_size))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer(\"pe\", pe.unsqueeze(0))  # Store positional encoding on the correct device\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Add positional encoding to input tensor.\"\"\"\n",
        "        return x + self.pe[:, :x.size(1), :].to(x.device)\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    \"\"\"Single Transformer Block\"\"\"\n",
        "    def __init__(self, embed_size, num_heads, ff_hidden_size, dropout):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.attention = MultiHeadAttention(embed_size, num_heads)\n",
        "        self.norm1 = nn.LayerNorm(embed_size)\n",
        "        self.norm2 = nn.LayerNorm(embed_size)\n",
        "        self.feed_forward = FeedForward(embed_size, ff_hidden_size, dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, query, key, value, mask):\n",
        "        attention_output = self.attention(query, key, value, mask)\n",
        "        x = self.norm1(query + self.dropout(attention_output))\n",
        "        ff_output = self.feed_forward(x)\n",
        "        return self.norm2(x + self.dropout(ff_output))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "qlF0ectaKHwF"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 4. Complete Transformer Model\n",
        "\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    \"\"\"Complete Transformer Model\"\"\"\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, embed_size, num_heads, num_layers, ff_hidden_size, dropout=0.1):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.src_embedding = nn.Embedding(src_vocab_size, embed_size)\n",
        "        self.tgt_embedding = nn.Embedding(tgt_vocab_size, embed_size)\n",
        "        self.positional_encoding = PositionalEncoding(embed_size)\n",
        "        self.encoder_layers = nn.ModuleList([\n",
        "            TransformerBlock(embed_size, num_heads, ff_hidden_size, dropout) for _ in range(num_layers)\n",
        "        ])\n",
        "        self.decoder_layers = nn.ModuleList([\n",
        "            TransformerBlock(embed_size, num_heads, ff_hidden_size, dropout) for _ in range(num_layers)\n",
        "        ])\n",
        "        self.fc_out = nn.Linear(embed_size, tgt_vocab_size)\n",
        "\n",
        "    def forward(self, src, tgt, src_mask=None, tgt_mask=None):\n",
        "        src = self.positional_encoding(self.src_embedding(src))\n",
        "        tgt = self.positional_encoding(self.tgt_embedding(tgt))\n",
        "        for layer in self.encoder_layers:\n",
        "            src = layer(src, src, src, src_mask)\n",
        "        for layer in self.decoder_layers:\n",
        "            tgt = layer(tgt, src, src, tgt_mask)\n",
        "        return self.fc_out(tgt)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "pwDYA5ndKJlR"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 5. Training Loop\n",
        "\n",
        "\n",
        "def train_model(model, dataloader, optimizer, criterion, num_epochs):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        for src, tgt in tqdm(dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n",
        "            src, tgt = src.to(device), tgt.to(device)\n",
        "            tgt_input = tgt[:, :-1]\n",
        "            tgt_output = tgt[:, 1:]\n",
        "            outputs = model(src, tgt_input)\n",
        "            loss = criterion(outputs.view(-1, outputs.size(-1)), tgt_output.contiguous().view(-1))\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}, Loss: {total_loss/len(dataloader):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "QEMy5TEAKLjk"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 6. Evaluation and Inference\n",
        "\n",
        "\n",
        "def translate_validation_data(model, tokenizer_src, tokenizer_tgt, val_sentences):\n",
        "    model.eval()\n",
        "    translations = {}\n",
        "    with torch.no_grad():\n",
        "        for key, sentence in tqdm(val_sentences.items(), desc=\"Translating\"):\n",
        "            encoded_sentence = torch.tensor(tokenizer_src.encode(sentence).ids).unsqueeze(0).to(device)\n",
        "            translation_ids = greedy_decode(model, encoded_sentence)\n",
        "            translation = tokenizer_tgt.decode(translation_ids, skip_special_tokens=True)\n",
        "            translations[key] = translation\n",
        "\n",
        "            # Print the translation for each sentence as it is processed\n",
        "            #print(f\"Source: {sentence}\")\n",
        "            #print(f\"Translation: {translation}\")\n",
        "            #print(\"-\" * 50)\n",
        "    return translations\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Uc-DhNI8KNT0"
      },
      "outputs": [],
      "source": [
        "def greedy_decode(model, src_sentence, max_len=50, start_token_id=2, end_token_id=3):\n",
        "    model.eval()\n",
        "\n",
        "    # Ensure src_sentence is a long tensor\n",
        "    src_sentence = src_sentence.to(device).long()  # Convert to torch.long\n",
        "\n",
        "    tgt_sequence = torch.tensor([[start_token_id]], device=device, dtype=torch.long)  # Start token\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(max_len):\n",
        "            # Pass the source sentence and target sequence to the model\n",
        "            output = model(src_sentence, tgt_sequence)\n",
        "\n",
        "            # Get the token ID with the highest probability for the next position\n",
        "            next_token_id = output[:, -1, :].argmax(dim=-1).item()\n",
        "\n",
        "            # Append the new token to the sequence\n",
        "            tgt_sequence = torch.cat(\n",
        "                [tgt_sequence, torch.tensor([[next_token_id]], device=device, dtype=torch.long)], dim=1\n",
        "            )\n",
        "\n",
        "            # Stop if the end token is generated\n",
        "            if next_token_id == end_token_id:\n",
        "                break\n",
        "\n",
        "    return tgt_sequence.squeeze(0).tolist()  # Return the decoded sequence as a list of token IDs\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_validation_file(\n",
        "    val_file_path,\n",
        "    output_file_base,\n",
        "    model,\n",
        "    tokenizer_src,\n",
        "    tokenizer_tgt,\n",
        "    device,\n",
        "    max_len=50\n",
        "):\n",
        "    \"\"\"Translate validation data and save results.\"\"\"\n",
        "    # Load validation data\n",
        "    val_data = load_validation_data(val_file_path)\n",
        "    val_df = pd.DataFrame(list(val_data.items()), columns=[\"id\", \"source\"])\n",
        "\n",
        "    translated_sentences = []\n",
        "\n",
        "    for idx, row in tqdm(val_df.iterrows(), total=len(val_df), desc=\"Translating\"):\n",
        "        text_id = row['id']\n",
        "        source_sentence = row['source']\n",
        "\n",
        "        # Translate the sentence using greedy_decode\n",
        "        src_encoded = torch.tensor(tokenizer_src.encode(source_sentence).ids).unsqueeze(0).to(device)\n",
        "        translation_ids = greedy_decode(model, src_encoded, max_len=max_len)\n",
        "        translated_sentence = tokenizer_tgt.decode(translation_ids, skip_special_tokens=True)\n",
        "\n",
        "        translated_sentences.append({\"id\": text_id, \"translated\": translated_sentence})\n",
        "\n",
        "        # Print progress\n",
        "        #print(f\"[ID: {text_id}] Source: {source_sentence}\\nTranslated: {translated_sentence}\\n\")\n",
        "\n",
        "    # Create output DataFrame\n",
        "    output_df = pd.DataFrame(translated_sentences)\n",
        "\n",
        "    # Save results\n",
        "    output_df.to_csv(f\"{output_file_base}_encoded.csv\", index=False, encoding='utf-8')\n",
        "    output_df.to_csv(f\"{output_file_base}_unencoded.csv\", index=False, encoding=None)\n",
        "    output_df.to_json(f\"{output_file_base}_encoded.json\", orient='records', lines=True, force_ascii=True)\n",
        "    output_df.to_json(f\"{output_file_base}_unencoded.json\", orient='records', lines=True, force_ascii=False)\n",
        "\n",
        "    print(f\"Translations saved as:\\n\"\n",
        "          f\"  CSV (encoded): {output_file_base}_encoded.csv\\n\"\n",
        "          f\"  CSV (unencoded): {output_file_base}_unencoded.csv\\n\"\n",
        "          f\"  JSON (encoded): {output_file_base}_encoded.json\\n\"\n",
        "          f\"  JSON (unencoded): {output_file_base}_unencoded.json\")\n"
      ],
      "metadata": {
        "id": "Xc7Wm-kyBmzQ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbWX6cXmKQ2o",
        "outputId": "9db4c604-c657-4735-ccdd-436eb607f082"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer saved to tokenizer_src.json\n",
            "Tokenizer saved to tokenizer_tgt.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10: 100%|██████████| 2152/2152 [03:23<00:00, 10.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 7.8026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10: 100%|██████████| 2152/2152 [03:29<00:00, 10.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Loss: 6.9923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10: 100%|██████████| 2152/2152 [03:29<00:00, 10.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Loss: 6.4522\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10: 100%|██████████| 2152/2152 [03:29<00:00, 10.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Loss: 5.9993\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10: 100%|██████████| 2152/2152 [03:28<00:00, 10.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Loss: 5.6031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/10: 100%|██████████| 2152/2152 [03:28<00:00, 10.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6, Loss: 5.2459\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/10: 100%|██████████| 2152/2152 [03:28<00:00, 10.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7, Loss: 4.9136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/10: 100%|██████████| 2152/2152 [03:28<00:00, 10.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8, Loss: 4.6023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/10: 100%|██████████| 2152/2152 [03:28<00:00, 10.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, Loss: 4.3055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/10: 100%|██████████| 2152/2152 [03:28<00:00, 10.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Loss: 4.0276\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 6. Main Workflow\n",
        "\n",
        "\n",
        "# Paths\n",
        "train_file = \"/content/train_data1.json\"\n",
        "\n",
        "# Step 1: Load training and validation data\n",
        "source_sentences, target_sentences = load_training_data(train_file)\n",
        "\n",
        "# Step 2: Tokenize and preprocess\n",
        "tokenizer_src = train_bpe_tokenizer(source_sentences, 30000, \"tokenizer_src.json\")\n",
        "tokenizer_tgt = train_bpe_tokenizer(target_sentences, 30000, \"tokenizer_tgt.json\")\n",
        "src_encoded = encode_sentences(tokenizer_src, source_sentences, max_len=50)\n",
        "tgt_encoded = encode_sentences(tokenizer_tgt, target_sentences, max_len=50)\n",
        "\n",
        "# Step 3: Train model\n",
        "model = Transformer(30000, 30000, 256, 8, 6, 2048, 0.1).to(device)\n",
        "dataloader = DataLoader(TranslationDataset(src_encoded, tgt_encoded), batch_size=32, collate_fn=collate_fn)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "train_model(model, dataloader, optimizer, criterion, 10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "uBKHbFnHKetu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21d7cdd5-f827-43d4-986e-219b5a3f1c41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Translating: 100%|██████████| 19672/19672 [2:15:55<00:00,  2.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translations saved to translated_test_data1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Step 4: Validate and save translations\n",
        "\n",
        "train_file = \"/content/train_data1.json\"\n",
        "val_file = \"/content/test_data1_final.json\"\n",
        "val_sentences = load_validation_data(val_file)\n",
        "translations = translate_validation_data(model, tokenizer_src, tokenizer_tgt, val_sentences)\n",
        "save_translations(translations, \"translated_test_data1.json\")\n",
        "\n",
        "# # Step 5: Translate Validation File (newly integrated)\n",
        "# translate_validation_file(\n",
        "#     val_file_path='/content/test_data1_final.json',\n",
        "#     output_file_base='/content/translated_test',\n",
        "#     model=model,\n",
        "#     source_vocab=tokenizer_src.get_vocab(),\n",
        "#     target_vocab=tokenizer_tgt.get_vocab(),\n",
        "#     device=device\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rsajqpkbY_6c"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
